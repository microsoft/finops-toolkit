/// Name of the Azure DataLake Gen2 storage account to pull data from.
expression 'Storage URL' = "https://demohubupzaljui2bxfm.dfs.core.windows.net/ingestion" meta [IsParameterQuery=true, Type="Text", IsParameterQueryRequired=false]
	lineageTag: 421c1232-0e40-45a4-bc59-257ce648478c
	queryGroup: '🛠️ Setup'

	annotation PBI_ResultType = Text

	annotation PBI_NavigationStepName = Navigation

expression RangeStart = null meta [IsParameterQuery=true, Type="DateTime", IsParameterQueryRequired=false]
	lineageTag: 90085870-f708-4bc2-90c1-3a343e88a26b
	queryGroup: '🛠️ Setup'

	annotation PBI_ResultType = Null

	annotation PBI_NavigationStepName = Navigation

expression RangeEnd = null meta [IsParameterQuery=true, Type="DateTime", IsParameterQueryRequired=false]
	lineageTag: 695f1d3b-7b1a-49fa-8d83-f2c25dc787de
	queryGroup: '🛠️ Setup'

	annotation PBI_ResultType = Null

	annotation PBI_NavigationStepName = Navigation

/// Loads data from the configured storage account for FinOps hubs or with Cost Management exports.
/// 
/// Learn more about FinOps hubs @ https://aka.ms/finops/hubs
expression ftk_Storage = ```
		(optional datasetType as text) =>
		let
		    // Config
		    url   = #"Storage URL",
		    end   = if RangeEnd <> null then RangeEnd else null,
		    start = 
		        if RangeStart <> null then RangeStart 
		        else if #"Number of Months" <> null and #"Number of Months" > 0 then Date.AddMonths(if RangeEnd <> null then RangeEnd else Date.StartOfMonth(Date.From(DateTime.LocalNow())), -#"Number of Months"+1)
		        else null,
		    data = if datasetType <> null and datasetType <> "" then Text.Lower(datasetType) else "focuscost",
		
		    // Determine if the URL is a hub URL
		    urlSegments  = Text.Split(url, "/"),
		    isHubStorage = List.Count(urlSegments) = 4 and urlSegments{3} = "ingestion",                               // Storage path = https://{storage-account-uri}/ingestion/{dataset}/{yyyy}/{MM}/{scope}
		    isHubOneLake = List.Count(urlSegments) = 7 and urlSegments{5} = "Files" and urlSegments{6} = "ingestion",  // OneLake path = https://{onelake-uri}/{guid}/{guid}/Files/ingestion/{dataset}/{yyyy}/{MM}/{scope}
		    containerOffset = if isHubOneLake then 6 else 3,
		
		    // Connect to ADLS
		    HubStorage = if isHubStorage or isHubOneLake then (
		        try let
		            DataStore = AzureStorage.DataLake(url),
		            FilterHub = Table.SelectRows(
		                DataStore, 
		                each [Attributes]?[Hidden]? <> true
		                    and [Extension] = ".parquet"
		                    and (
		                        data = Text.Lower(List.Last(List.RemoveLastN(Text.Split([Folder Path],"/"), 1))) // Supports 0.2-0.5 folder structure: //{storage-account-uri}/ingestion/{scope}/{yyyyMM}/{dataset}
		                        or data = Text.Lower(Text.Split([Folder Path],"/"){containerOffset+1}) // Supports 0.6 folder structure: .../ingestion/{dataset}/{yyyy}/{MM}/{scope}
		                        // Handle 0.7 dataset folder names
		                        or (data = "focuscost"                  and "Costs"                   = Text.Split([Folder Path],"/"){containerOffset+1})
		                        or (data = "pricesheet"                 and "Prices"                  = Text.Split([Folder Path],"/"){containerOffset+1})
		                        or (data = "reservationdetails"         and "CommitmentDiscountUsage" = Text.Split([Folder Path],"/"){containerOffset+1})
		                        or (data = "reservationrecommendations" and "Recommendations"         = Text.Split([Folder Path],"/"){containerOffset+1})
		                        or (data = "reservationtransactions"    and "Transactions"            = Text.Split([Folder Path],"/"){containerOffset+1})
		                    )
		            ),
		            HubMonth  = Table.AddColumn(
		                FilterHub,
		                "StartDate",
		                each try
		                    // Supports 0.6+ folder structure: {dataset}/{yyyy}/{MM}/{scope}
		                    if Text.Length(Text.Split([Folder Path],"/"){containerOffset+2}) = 4 and Text.Length(Text.Split([Folder Path],"/"){containerOffset+3}) = 2 then
		                        _toMonth(Text.Split([Folder Path],"/"){containerOffset+2} & Text.Split([Folder Path],"/"){containerOffset+3})
		                    // Supports 0.2-0.5 folder structure: {scope}/{yyyyMM}/{dataset}
		                    else  _toMonth(List.Last(List.RemoveLastN(List.RemoveLastN(Text.Split([Folder Path],"/"), 1), 1)))
		                otherwise _toMonth(List.Last(List.RemoveLastN(List.RemoveLastN(Text.Split([Folder Path],"/"), 1), 1))),
		                type date
		            )
		        in HubMonth otherwise null
		    ) else null,
		    hasHubData = (HubStorage = null or Table.RowCount(HubStorage) = 0) = false,
		    ExpStorage = if hasHubData then null else (
		        try let
		            // Filter out anything that doesn't look like a CM export
		            DataStore = AzureStorage.DataLake(url),
		            DataStoreRows = Table.SelectRows(DataStore, each [Attributes]?[Hidden]? <> true),
		            Segments  = Table.AddColumn(Table.AddColumn(DataStoreRows,
		                "Segments",     each Text.Split(Text.Replace(Text.Trim([Folder Path], "/"), "https://", ""), "/")),
		                "SegmentCount", each List.Count([Segments])),
		            FilterExports = Table.SelectRows(Segments,
		                each ([SegmentCount] >= 7 and Text.Length([Segments]{[SegmentCount]-1}) = 36 and Text.Length([Segments]{[SegmentCount]-2}) = 12 and Text.Length([Segments]{[SegmentCount]-3}) = 17)
		                    or ([SegmentCount] >= 6 and Text.Length([Segments]{[SegmentCount]-1}) = 36 and Text.Length([Segments]{[SegmentCount]-2}) = 17) // Exports v2 preview bug had a missing folder (remove after June 2025)
		                    or ([SegmentCount] >= 5 and Text.Length([Segments]{[SegmentCount]-1}) = 36 and data = "reservationrecommendations") // Reservation recommendations do not have a date folder
		            ),
		
		            // Find the paths that hae the desired dataset with overwriting enabled (so we don't show duplicate data)
		            DatasetPaths = Table.SelectColumns(
		                Table.SelectRows(
		                    Table.AddColumn(FilterExports, "Json", each try if [Name] = "manifest.json" then Json.Document([Content]) else null otherwise null), 
		                    each try [Name] = "manifest.json" 
		                        and Text.Lower([Json][exportConfig][type]) = data
		                        and [Json][deliveryConfig][dataOverwriteBehavior] = "OverwritePreviousReport"
		                        otherwise false
		                ),
		                {"Folder Path"}
		            ),
		            FilterExpData = Table.SelectRows(FilterExports, each ([Extension] = ".parquet" or [Extension] = ".csv") and List.Contains(Table.Column(DatasetPaths, "Folder Path"), [Folder Path])),
		            ExportMonth = Table.AddColumn(FilterExpData, "StartDate", each if data = "reservationrecommendations" then null else _toMonth([Segments]{[SegmentCount]-(if Text.Length([Segments]{[SegmentCount]-2}) = 17 then 2 else 3)}), type date)
		        in ExportMonth
		        otherwise null
		    ),
		    Source = if hasHubData then HubStorage else ExpStorage,
		
		    // NOTE: Do not convert to UTC - UTC dates can show as the previous month based on the local timezone
		    _toMonth = (s) => Date.FromText(Text.Range(s, 0, 4) & "-" & Text.Range(s, 4, 2) & "-01"),
		
		    // Only process files for months within the date range
		    FilterFilesByDate =
		        if start = null and end = null then Source
		        else Table.SelectRows(
		            Table.AddColumn(Source, "EndDate", each if [StartDate] = null then null else Date.EndOfMonth([StartDate]), type datetime), 
		            each (start = null or [StartDate] = null or [StartDate] >= Date.StartOfMonth(Date.From(start))) and (end = null or [EndDate] = null or [EndDate] <= Date.EndOfMonth(Date.From(end)))
		        ),
		    AddMetadata = Table.AddColumn(FilterFilesByDate, "Metadata", each 
		        if Text.Lower([Extension]) = ".parquet" and datasetType = "focuscost" then ftk_Metadata([Content], "ChargePeriodStart")
		        else null ),
		    ExpandMetadata = Table.ExpandTableColumn(AddMetadata, "Metadata", {"Min"}, {"ChargePeriodStart"}),
		    FilterMetadata = Table.SelectRows(ExpandMetadata, each (start = null or [ChargePeriodStart] = null or [ChargePeriodStart] >= ftk_DatetimeToJulianDate(start)) and (end = null or [ChargePeriodStart] = null or [ChargePeriodStart] < ftk_DatetimeToJulianDate(end))),
		    // Extract
		    _dataNotFound = () =>
		        if isHubStorage or isHubOneLake then "HubDataNotFound: No " & data & " data found in the storage account (" & Text.SplitAny(url, "/."){2} & "). Please confirm data was exported and processed by hub ingestion pipelines. Refer to the troubleshooting guide for assistance: https://aka.ms/finops/hubs/troubleshoot."
		        else "ExportDataNotFound: No " & data & " exports found in the storage path. Please confirm exports were run and configured to push data to the storage account (" & Text.SplitAny(url, "/."){2} & "), container (" & Text.Split(url, "/"){3} & "), and path (" & Text.Combine(List.RemoveFirstN(Text.Split(url, "/"), 3), "/") & ").",
		    _parseCsv = (d) => Table.PromoteHeaders(Csv.Document(d, [Delimiter=",", Encoding=1252, QuoteStyle=QuoteStyle.Csv, CsvStyle=CsvStyle.QuoteAlways]), [PromoteAllScalars=true]),
		    _getColumnRenames = (tbl) =>
		        let
		            // Remove spaces and capitalize all columns
		            _original = Table.ColumnNames(tbl),
		            _updated = List.Transform(_original, each Text.Replace(Text.Upper(Text.Start(_, 1)) & Text.Range(_, 1), " ", "")),
		            columnRenames = List.Zip({_original, _updated})
		        in
		            columnRenames
		    ,
		    ReadContent = if FilterFilesByDate = null then null else Table.SelectRows(
		        Table.SelectColumns(
		            Table.AddColumn(FilterMetadata, "Data",
		                each if [Extension] = ".parquet" then Parquet.Document([Content]) 
		                else if [Extension] = ".gz"      then _parseCsv(Binary.Decompress([Content], Compression.GZip)) 
		                else if [Extension] = ".csv"     then _parseCsv([Content])
		                else [Content]
		            ),
		            {"Data"}
		        ),
		        each Table.RowCount([Data]) > 0
		    ),
		    ExtractColumns =
		        if ReadContent <> null and Table.RowCount(ReadContent) > 0 then
		            Table.ExpandTableColumn(ReadContent, "Data", List.Distinct(List.Combine(List.Transform(ReadContent[Data], each Table.ColumnNames(_)))))
		        else if data = "focuscost" then
		            #table(
		                { "BilledCost", "BillingAccountId", "BillingAccountName", "BillingAccountType", "BillingCurrency", "BillingPeriodEnd", "BillingPeriodStart", "ChargeCategory", "ChargeClass", "ChargeDescription", "ChargeFrequency", "ChargePeriodEnd", "ChargePeriodStart", "CommitmentDiscountCategory", "CommitmentDiscountId", "CommitmentDiscountName", "CommitmentDiscountStatus", "CommitmentDiscountType", "ConsumedQuantity", "ConsumedUnit", "ContractedCost", "ContractedUnitPrice", "EffectiveCost", "InvoiceIssuerName", "ListCost", "ListUnitPrice", "PricingCategory", "PricingQuantity", "PricingUnit", "ProviderName", "PublisherName", "RegionId", "RegionName", "ResourceId", "ResourceName", "ResourceType", "ServiceCategory", "ServiceName", "SkuId", "SkuPriceId", "SubAccountId", "SubAccountName", "SubAccountType", "Tags", "x_AccountId", "x_AccountName", "x_AccountOwnerId", "x_BilledCostInUsd", "x_BilledUnitPrice", "x_BillingAccountId", "x_BillingAccountName", "x_BillingExchangeRate", "x_BillingExchangeRateDate", "x_BillingProfileId", "x_BillingProfileName", "x_ContractedCostInUsd", "x_CostAllocationRuleName", "x_CostCenter", "x_CustomerId", "x_CustomerName", "x_EffectiveCostInUsd", "x_EffectiveUnitPrice", "x_InvoiceId", "x_InvoiceIssuerId", "x_InvoiceSectionId", "x_InvoiceSectionName", "x_ListCostInUsd", "x_PartnerCreditApplied", "x_PartnerCreditRate", "x_PricingBlockSize", "x_PricingCurrency", "x_PricingSubcategory", "x_PricingUnitDescription", "x_PublisherCategory", "x_PublisherId", "x_ResellerId", "x_ResellerName", "x_ResourceGroupName", "x_ResourceType", "x_ServicePeriodEnd", "x_ServicePeriodStart", "x_SkuDescription", "x_SkuDetails", "x_SkuIsCreditEligible", "x_SkuMeterCategory", "x_SkuMeterId", "x_SkuMeterName", "x_SkuMeterSubcategory", "x_SkuOfferId", "x_SkuOrderId", "x_SkuOrderName", "x_SkuPartNumber", "x_SkuRegion", "x_SkuServiceFamily", "x_SkuTerm", "x_SkuTier" },
		                {} // {{ null, null, null, null, null, null, null, null, null, _dataNotFound(), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null }}
		            )
		        else if data = "pricesheet" then
		            #table(
		                { "BasePrice", "CurrencyCode", "EffectiveEndDate", "EffectiveStartDate", "EnrollmentNumber", "IncludedQuantity", "MarketPrice", "MeterCategory", "MeterID", "MeterName", "MeterRegion", "MeterSubCategory", "MeterType", "OfferID", "PartNumber", "PriceType", "Product", "ProductID", "ServiceFamily", "SkuID", "Term", "UnitOfMeasure", "UnitPrice" },
		                {} // {{ null, null, null, null, null, null, null, null, null, _dataNotFound(), null, null, null, null, null, null, null, null, null, null, null, null, null }}
		            )
		        else if data = "reservationdetails" then
		            #table(
		                { "InstanceFlexibilityGroup", "InstanceFlexibilityRatio", "InstanceId", "Kind", "ReservationId", "ReservationOrderId", "ReservedHours", "SkuName", "TotalReservedQuantity", "UsageDate", "UsedHours" },
		                {} // {{ null, null, null, null, null, null, null, _dataNotFound(), null, null, null }}
		            )
		        else if data = "reservationtransactions" then
		            #table(
		                { "AccountName", "AccountOwnerEmail", "Amount", "ArmSkuName", "BillingFrequency", "BillingMonth", "CostCenter", "Currency", "CurrentEnrollmentId", "DepartmentName", "Description", "EventDate", "EventType", "MonetaryCommitment", "Overage", "PurchasingEnrollment", "PurchasingSubscriptionGuid", "PurchasingSubscriptionName", "Quantity", "Region", "ReservationOrderId", "ReservationOrderName", "Term" },
		                {} // {{ null, null, null, _dataNotFound(), null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null }}
		            )
		        else if data = "reservationrecommendations" then
		            #table(
		                { "CostWithNoReservedInstances", "FirstUsageDate", "InstanceFlexibilityGroup", "InstanceFlexibilityRatio", "Location", "LookBackPeriod", "MeterId", "NetSavings", "NormalizedSize", "RecommendedQuantity", "RecommendedQuantityNormlized", "ResourceType", "SKU", "Scope", "SkuProperties", "Term", "TotaCostWithReservedInstances" },
		                {} // {{ null, null, null, null, null, null, null, null, null, null, null, _dataNotFound(), null, null, null, null }}
		            )
		        else
		            #table(
		                { "Error" },
		                {{ _dataNotFound() }}
		            ),
		
		    // Fix column name inconsistencies across channels
		    CleanColumns = if data = "focuscost" then ExtractColumns else List.Accumulate(
		        List.Select(_getColumnRenames(ExtractColumns), each _{0} <> _{1}),
		        ExtractColumns,
		        (state, columns) =>
		            // Copy old value to a temp column, then remove original columns, then rename the temp column
		            Table.RenameColumns(
		                Table.RemoveColumns(
		                    Table.AddColumn(state, "Temp" & columns{1}, each if Record.Field(_, columns{0}) <> null then Record.Field(_, columns{0}) else Record.Field(_, columns{1})),
		                    columns
		                ),
		                {{"Temp" & columns{1}, columns{1}}}
		            )
		    ),
		
		    // Only pull from the predefined date range (if specified)
		    _parseDate = (d) =>
		        let
		            segments = if d = null then null else Text.SplitAny(Text.From(d), "/- T"),
		            output =
		                try Number.From(Date.From(
		                            if Text.Length(segments{0}) = 4 then segments{0} & "-" & Text.PadStart(segments{1}, 2, "0") & "-" & Text.PadStart(segments{2}, 2, "0")
		                    else if Text.Length(segments{2}) = 4 then segments{2} & "-" & Text.PadStart(segments{0}, 2, "0") & "-" & Text.PadStart(segments{1}, 2, "0")
		                    else d
		                )) otherwise segments
		        in output,
		    RefreshDate = Table.AddColumn(
		        Table.ReplaceValue(CleanColumns, "", null, Replacer.ReplaceValue, Table.ColumnsOfType(CleanColumns, {type text, type any})),
		        "x_IncrementalRefreshDate",
		            each _parseDate(
		                if data = "focuscost"                    then [ChargePeriodStart]
		                else if data = "pricesheet"              then [EffectiveStartDate]
		                else if data = "reservationdetails"      then [UsageDate]
		                else if data = "reservationtransactions" then [EventDate]
		                else null // Will not support incremental refresh
		            )
		        ),
		    FilterRowsByDate = if (start = null and end = null) then RefreshDate else Table.SelectRows(RefreshDate, each
		        (start = null or [x_IncrementalRefreshDate] = null or [x_IncrementalRefreshDate] >= Number.From(DateTime.From(start)))
		        and (end = null or [x_IncrementalRefreshDate] = null or [x_IncrementalRefreshDate] < Number.From(DateTime.From(end)))
		    ),
		
		    // TODO: Try using "_" instead of "FilterRowsByDate"
		    CustomColumns = Table.AddColumn(Table.AddColumn(Table.AddColumn(FilterRowsByDate,
		        "x_SourceType", each data),
		        "x_SourceVersion",
		            // TODO: Extract from the manifest
		            each if data = "focuscost"                  then (if Table.HasColumns(FilterRowsByDate, {"ChargeSubcategory"}) and [ChargeSubcategory] <> null then "1.0-preview(v1)" else "1.0")
		            else if data = "pricesheet"                 then "2023-05-01"
		            else if data = "reservationdetails"         then "2023-05-01"
		            else if data = "reservationtransactions"    then "2023-05-01"
		            else if data = "reservationrecommendations" then "2023-05-01"
		            else null
		        ),
		        "x_BillingAccountAgreement",
		            each if data = "focuscost"                  then (
		                if [BillingAccountId] = [SubAccountId] then "MOSA"
		                else if ftk_ParseResourceName([BillingAccountId]) = [x_BillingAccountId] then "EA"
		                else if ftk_ParseResourceName([BillingAccountId]) = [x_BillingProfileId] then (if [InvoiceIssuerName] = "Microsoft" then "MCA" else "MPA")
		                else "Unknown"
		            )
		            else if data = "pricesheet"                 then (if Table.HasColumns(FilterRowsByDate, "EnrollmentNumber") and [EnrollmentNumber] <> null then "EA" else "MCA") // TODO: Can we detect MPA separately?
		            else if data = "reservationdetails"         then "Unknown" // TODO: Consider using export manifest if we get feedback that this should always be available
		            else if data = "reservationtransactions"    then (if Table.HasColumns(FilterRowsByDate, "CurrentEnrollmentId") and [CurrentEnrollmentId] <> null then "EA" else "MCA") // TODO: Can we detect MPA separately?
		            else if data = "reservationrecommendations" then (if Table.HasColumns(FilterRowsByDate, "Scope") and [Scope] <> null then "EA" else "MCA")
		            else "Unknown"
		    ),
		    Output = Table.SelectColumns(CustomColumns, List.Sort(Table.ColumnNames(CustomColumns)))
		in
		    Output
		```
	lineageTag: 1195459e-bb6d-4ef2-8823-5f63c16fbcf5
	queryGroup: Functions

	annotation PBI_ResultType = Function

	annotation PBI_NavigationStepName = Navigation

expression '▶️  START HERE' = ```
		let
		    // Storage
		    StorageUrl = #"Storage URL",
		    UrlSegments = if StorageUrl <> null then Text.Split(StorageUrl, "/") else {},
		    UrlSegmentCount = List.Count(UrlSegments),
		    StorageCheck = 
		        if StorageUrl = "" or StorageUrl = null then {"✖ Invalid", "Storage URL not specified."}
		        else if Text.StartsWith(StorageUrl, "https://") = false then {"✖ Invalid", "Storage URL must be a valid HTTPS path."} 
		        else if (UrlSegmentCount = 4 and Text.Lower(UrlSegments{3}) = "ingestion") or (UrlSegmentCount = 7 and Text.Lower(UrlSegments{5}) = "Files" and Text.Lower(UrlSegments{6}) = "ingestion") then (
		            let
		                // Looks like hubs; try to get hub version
		                Settings = try Json.Document(AzureStorage.DataLake(StorageUrl & (if UrlSegmentCount = 3 then "/config" else "/../config")){[Name="settings.json"]}[Content], 1252) otherwise null,
		                HubVersion = if Settings <> null then try Settings[version] otherwise null else null,
		                Output = 
		                    if HubVersion = null then (
		                        if UrlSegmentCount = 4                                               and Text.Lower(UrlSegments{3}) = "ingestion" then {"❓️ Unconfirmed", "Unable to confirm FinOps hub version from storage: " & Text.Split(StorageUrl, "."){0} & "."}
		                        else if UrlSegmentCount = 7 and Text.Lower(UrlSegments{5}) = "Files" and Text.Lower(UrlSegments{6}) = "ingestion" then {"❓️ Unconfirmed", "Unable to confirm FinOps hub version from OneLake: " & Text.Split(StorageUrl, "."){0} & "."}
		                        else {"✖️ Invalid", "Configured storage account does not have FinOps hubs deployed."}
		                    )
		                    else {"✔️ Specified", "Will use FinOps hub v" & HubVersion & " storage: " & Text.Split(StorageUrl, "."){0} & "."}
		            in
		                Output
		        )
		        else if (try AzureStorage.DataLake(StorageUrl) otherwise null) <> null then {"✔️ Specified", "Will use exports in storage account: " & Text.Split(StorageUrl, "."){0} & "."}
		        // TODO: Read export manifests from the storage account to validate data is available
		        else {"✖️ Invalid", "Unable to connect to the specified storage account: " & Text.Split(StorageUrl, "."){0} & "."},
		
		    // Incremental refresh
		    DateEnd = RangeEnd,
		    DateStart = RangeStart,
		    DateMonths = #"Number of Months",
		    DateStartEffective = if DateStart <> null and DateStart <> "" then DateStart else Date.AddMonths(if DateEnd <> null and DateEnd <> "" then DateEnd else Date.AddMonths(Date.StartOfMonth(DateTime.LocalNow()), 1), -DateMonths+1),
		    _formatDate = (d) => try DateTime.ToText(d, [Format="MMM d, yyyy"]) otherwise d,
		    DateStartFormat = 
		        if (DateStart = null or DateStart = "") and (DateMonths = null or DateMonths < 1) then "*"
		        else if (DateStart = null or DateStart = "") and DateMonths <> null and DateMonths >= 1 then _formatDate(DateStartEffective)
		        else _formatDate(DateStart),
		    DateEndFormat = if DateEnd = null or DateEnd = "" then "*" else _formatDate(DateEnd),
		    DateValue = 
		        if DateStartFormat = "*" and DateEndFormat = "*" then "(no dates)" else DateStartFormat & " - " & DateEndFormat,
		    DateCheck =
		        // TODO: Catch when DateEnd and DateMonths create a start date in the future
		        if DateValue = "(no dates)"   then {"⚠️ Warning", "Will pull all data. May fail if over $2-5M."}
		        else if DateStart <> null and DateStart <> "" and DateEndFormat = "*" then {"⚠️ Warning", "Will pull all data after start date. May fail if over $2-5M."}
		        else if (DateStart = null or DateStart = "")  and DateEndFormat = "*" then {"✔️ Specified", "Will pull data for the last " & (if DateMonths = 1 then "1 month" else (Text.From(DateMonths) & " months")) & "."}
		        else if DateStartFormat = "*" then {"⚠️ Warning", "Will pull all data before end date. May fail if over $2-5M."}
		        else if DateStart <> null and DateStart <> "" and DateStart > DateEnd then {"✖ Invalid", "The start date must be before the end date."}
		        else if DateStart <> null and DateStart <> "" and DateStart < DateEnd then try {"✔️ Specified", "Will pull data for " & Number.ToText(Duration.Days(DateEnd - DateStart)) & " days."} otherwise {"✖ Invalid", "Unable to parse dates: " & DateStart & " - " & DateEnd & "."}
		        else if DateStart = null and DateMonths <> null and DateMonths < 1 then {"✖ Invalid", "The number of months must be more 1 or more (empty for all)."}
		        else if DateStart = null and DateMonths <> null and DateMonths > 0 then try {"✔️ Specified", "Will pull data for " & Number.ToText(Duration.Days(DateEnd - DateStartEffective)) & " days."} otherwise {"✖ Invalid", "Unable to parse dates: " & DateStartEffective & " - " & DateEnd & "."}
		        else {"✖ Invalid", "Unable to confirm dates: " & (if DateStart = null then "(null)" else ("'"&Text.From(DateStart)&"'")) & " - " & (if DateEnd = null then "(null)" else ("'"&Text.From(DateEnd)&"'")) & " or # of months: " & (if DateMonths = null then "(null)" else ("'"&Text.From(DateMonths)&"'")) & "."},
		
		    // 
		    /*
		    Step1 = Table.InsertRows(#table({"Instructions", "Value", "Status", "Message"}, {}), 0, {
		        [ Instructions = "① Set the data source parameter on the left", Value = SourceType, Status = SourceCheck{0}, Message = SourceCheck{1} ],
		        [ Instructions = "        ➖ About exports @ https://aka.ms/finops/toolkit/exports", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ About FinOps hubs @ https://aka.ms/finops/hubs", Value = "", Status = "", Message = "" ],
		        [ Instructions = "", Value = "", Status = "", Message = "" ]
		    }),
		
		    MainChecks = Table.InsertRows(Step1, 4, 
		    */
		
		    MainChecks = Table.InsertRows(#table({"Instructions", "Value", "Status", "Message"}, {}), 0, {
		        [ Instructions = "① Set the storage URL on the left", Value = StorageUrl, Status = StorageCheck{0}, Message = StorageCheck{1} ],
		        [ Instructions = "        If using FinOps hubs:", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Go to your hub resource group", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Open Deployments > `hub` > Outputs", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Copy the 'HubUrlForPowerBI' value", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        If using exports:", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Go to your storage account", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Open Endpoints", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Copy the 'Data Lake Storage' value", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ➖ Optionally add a container or file path", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ", Value = "", Status = "", Message = "" ],
		        [ Instructions = "③ Optional: Set the desired date range", Value = DateValue, Status = DateCheck{0}, Message = DateCheck{1} ],
		        //[ Instructions = "        ➖ Dates are only required to support incremental refresh", Value = "", Status = "", Message = if DateCheck{0} = "⚠️ Warning" then "Incremental refresh requires dates." else if DateCheck{0} = "✔️ Specified" then "Please configure incremental refresh to support up to $2-5M/mo." else "" ],
		        [ Instructions = "        ➖ NOTE: Power BI only supports a total of $2-5M without incremental refresh", Value = "", Status = "", Message = "" ],
		        [ Instructions = "        ", Value = "", Status = "", Message = "" ]
		    })
		in
		    MainChecks
		```
	lineageTag: 6cfe80b8-1c4b-4c11-9916-43fc98b49dac
	queryGroup: '🛠️ Setup'

	annotation PBI_ResultType = Table

	annotation PBI_NavigationStepName = Navigation

/// Loads data from the configured FinOps hub.
/// 
/// Learn more @ https://aka.ms/finops/hubs
expression ftk_ParseResourceId = ```
		(id, getName) => 
		if id = null or id = "" then null else 
		let
		    // Handle implicit Microsoft.Resources RP names
		    updatedId = if Text.StartsWith(id, "/subscriptions/") or Text.StartsWith(id, "/tenants/") then "/providers/Microsoft.Resources" & id else id,
		
		    // Parse resource ID segments separately
		    allSegments = Text.Split(List.Last(Text.Split(updatedId, "/providers/")), "/"),
		    provider = allSegments{0},
		    _parseId = (evenOrOdd) => List.RemoveNulls(List.Transform({1..List.Count(allSegments)-1}, each if Number.Mod(_, 2) = evenOrOdd then allSegments{_} else null)),
		    nameSegments = _parseId(0),
		    typeSegments = _parseId(1),
		    
		    // Remove the sub ID if it's a child resource of the subscription
		    isChildOfSubscription = provider = "Microsoft.Resources" and Text.Lower(typeSegments{0}) = "subscriptions" and List.Count(typeSegments) > 1,
		    fullName = Text.Combine((if isChildOfSubscription then List.RemoveFirstN(nameSegments, 1) else nameSegments), "/"),
		
		    fullType = provider & "/" & Text.Combine(typeSegments, "/"),
		    result = if getName then fullName else fullType
		in
		    result
		```
	lineageTag: 47af7699-603d-457e-ac71-57d695f11fca
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

/// Loads data from the configured FinOps hub.
/// 
/// Learn more @ https://aka.ms/finops/hubs
expression ftk_ParseResourceName = (id) => ftk_ParseResourceId(id, true)
	lineageTag: 0dde2951-d866-4f3b-9c34-e324ce31541e
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

/// Loads data from the configured FinOps hub.
/// 
/// Learn more @ https://aka.ms/finops/hubs
expression ftk_ParseResourceType = (id) => ftk_ParseResourceId(id, false)
	lineageTag: e0916ea5-0653-40f5-ac6d-84ea4164cabe
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

/// Optional. Number of months to include in the report before the RangeEnd date. Ignored if RangeStart is specified. Default: (all available data).
expression 'Number of Months' = 1 meta [IsParameterQuery=true, Type="Number", IsParameterQueryRequired=false]
	lineageTag: 1d47668d-4de6-404c-8e53-f89a35081e8b
	queryGroup: '🛠️ Setup'

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Number

expression ftk_DatetimeToJulianDate = ```
		(InputDate) =>
		    let
		        StartDate = #date(1899, 12, 30),
		        NumberOfDays = Duration.Days(Date.From(InputDate) - StartDate),
		        JulianDay = NumberOfDays + 2415018.5 // 2415019 or 2415018.5 
		    in
		        JulianDay
		```
	lineageTag: 4b2bc0fe-5c3d-4275-ad19-3b4ff0b720e9
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

expression ftk_ImpalaToJulianDate =
		(binaryData) =>
		let
		    // Your 12-byte binary data
		    // binaryData = Binary.FromText("AAAAAAAAAADBiSUA", BinaryEncoding.Base64),
		    // Get the last 4 bytes
		    last4Bytes = Binary.Range(binaryData, 8, 4),
		    // Convert the binary to a list of numbers
		    listOfNumbers = Binary.ToList(last4Bytes),
		    // Reverse the list of numbers
		    reversedListOfNumbers = List.Reverse(listOfNumbers),
		    // Convert the list of numbers to an integer
		    number = List.Accumulate(reversedListOfNumbers, 0, (state, current) => state * 256 + current) - 0.5
		in
		    number
	lineageTag: 89863516-9c1f-4f21-aaf1-b84e73909525
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

expression ftk_Metadata =
		(fileContents, dateColumn as text) =>
		let
		  m = Parquet.Metadata(fileContents) as any,
		  Navigation = m[RowGroups],
		  #"Expanded Columns" = Table.ExpandTableColumn(Navigation, "Columns", {"MetaData"}, {"MetaData"}),
		  #"Expanded MetaData" = Table.ExpandRecordColumn(#"Expanded Columns", "MetaData", {"PathInSchema", "Statistics"}, {"PathInSchema", "Statistics"}),
		  #"Expanded PathInSchema" = Table.ExpandListColumn(#"Expanded MetaData", "PathInSchema"),
		  #"Filtered rows" = Table.SelectRows(#"Expanded PathInSchema", each ([PathInSchema] = dateColumn)),
		  #"Expanded Statistics" = Table.ExpandRecordColumn(#"Filtered rows", "Statistics", {"MaxValue", "MinValue"}, {"MaxValue", "MinValue"}),
		  #"Added min" = Table.AddColumn(#"Expanded Statistics", "Min", each if [MinValue] = null then null else ftk_ImpalaToJulianDate([MinValue])),
		  #"Added max" = Table.AddColumn(#"Added min", "Max", each if [MaxValue] = null then null else ftk_ImpalaToJulianDate([MaxValue])),
		  #"Removed other columns" = Table.SelectColumns(#"Added max", {"Min", "Max"}),
		  #"Removed duplicates" = Table.Distinct(#"Removed other columns")
		in
		  #"Removed duplicates"
	lineageTag: c697294c-e969-4248-8d51-2232bfbd8068
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

/// Optional. Experimental feature to join the prices with the cost to populate missing list and contracted unit price and calculate missing cost values. This enables calculating total savings. Allowed values = "TRUE", "FALSE".
/// 
/// This experimental feature is extremely slow to run and has not been fully tested. We are investigating alternative means to perform this join.
expression 'Experimental: Add Missing Prices' = false meta [IsParameterQuery=true, List={false, true}, DefaultValue=false, Type="Logical", IsParameterQueryRequired=false]
	lineageTag: 3664712f-0c0b-4565-8123-1161b5a8dba8
	queryGroup: '🛠️ Setup'

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Logical

/// Loads data from the configured storage account for FinOps hubs or with Cost Management exports.
/// 
/// Learn more about FinOps hubs @ https://aka.ms/finops/hubs
expression ftk_DemoFilter = () => if List.Contains({ "demohubupzaljui2bxfm", "kustohubbngtbihvy5t4a" }, Text.SplitAny(#"Storage URL", "/."){2}) then "| where subscriptionId in ('51f73f67-1f29-4120-863e-dd315f743fc1', '586f1d47-9dd9-43d5-b196-6e28f8405ff8', '64e355d7-997c-491d-b0c1-8414dccfcf42', '736af2bf-9fcb-4145-a19b-5b30b2b8949d', '73c0021f-a37d-433f-8baa-7450cb54eea6', '9ec51cfd-5ca7-4d76-8101-dd0a4abc5674', 'ed570627-0265-4620-bb42-bae06bcfa914')" else ""
	lineageTag: 4d4c22f9-d4dc-4c2e-9730-dbc47fa53b05
	queryGroup: Functions

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Function

/// Optional. Experimental feature to join the prices with the cost to populate missing list and contracted unit price and calculate missing cost values. This enables calculating total savings. Allowed values = "TRUE", "FALSE".
/// 
/// This experimental feature is extremely slow to run and has not been fully tested. We are investigating alternative means to perform this join.
expression 'Deprecated: Perform Extra Query Optimizations' = true meta [IsParameterQuery=true, List={false, true}, DefaultValue=true, Type="Logical", IsParameterQueryRequired=false]
	lineageTag: f22de62e-d0a2-4f18-be6a-86172ff55b17
	queryGroup: '🛠️ Setup'

	annotation PBI_NavigationStepName = Navigation

	annotation PBI_ResultType = Logical

